# Interesting-DL-Papers
List of DL papers on Interpretability, Learning from Limited Data and Information Bottleneck

## Visual Interpretation
[1] [Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer](https://arxiv.org/pdf/1612.03928.pdf)

[2] [Interpretable and Pedagogical Examples](https://arxiv.org/pdf/1711.00694.pdf)

[3] [Interpretable Explanations of Black Boxes by Meaningful Perturbation](https://arxiv.org/pdf/1704.03296.pdf)

[4] [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/pdf/1610.02391.pdf)

[5] [Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks](https://arxiv.org/pdf/1610.02391.pdf)


## Information Bottleneck
[1] [Compressing Neural Networks using the Variational Information Bottleneck](https://arxiv.org/pdf/1802.10399.pdf)

[2] [One Big Net For Everything](https://arxiv.org/pdf/1802.08864.pdf)

## Limited Data





